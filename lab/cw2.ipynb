{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producent Apache Kafka\n",
    "\n",
    "## Wersja z dostępem do środowiska\n",
    "\n",
    "Tą wersję można przejść również posiadając nowy obraz dockerowy i uruchomiony docker desktop na własnym komputerze.\n",
    "\n",
    "1. Przejdź do przeglądarki i uruchom stronę ze środowiskiem (w przypadku Docker uruchom `localhost:8888`).\n",
    "2. Uruchom (w jupyter lab za pomocą ikony terminala) nowy terminal\n",
    "\n",
    "3. Przejdź do katalogu głównego i wypisz listę wszystkich elementów. Sprawdź czy na liście znajduje się katalog `kafka`.\n",
    "\n",
    "   ```bash\n",
    "   cd ~\n",
    "   ls -all\n",
    "   ```\n",
    "4. Uruchom polecenie sprawdzające listę topiców serwera Kafki\n",
    "    ```bash\n",
    "    kafka/bin/kafka-topics.sh --list --bootstrap-server broker:9092\n",
    "    ```\n",
    "5. Dodaj topic o nazwie streaming\n",
    "   ```bash\n",
    "   kafka/bin/kafka-topics.sh --bootstrap-server broker:9092 --create --topic streaming\n",
    "   ```\n",
    "6. Sprawdź listę tematów ponownie upewniając się, że posiadasz temat `streaming`\n",
    "7. Uruchom nowy terminal i utwórz producenta w konsoli generującego dane do nowego topicu\n",
    "```bash\n",
    "kafka/bin/kafka-console-producer.sh --bootstrap-server broker:9092 --topic streaming\n",
    "```\n",
    "\n",
    "Aby sprawdzić czy wysyłanie wiadomości działa uruchom kolejne okno terminala i wpisz następującą komendę realizującą konsumenta w konsoli: \n",
    "\n",
    "```bash\n",
    "kafka/bin/kafka-console-consumer.sh --bootstrap-server broker:9092 --topic streaming --from-beginning\n",
    "```\n",
    "> Pamiętaj, aby uruchamiać komendy z odpowiedniego katalogu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponizszy kod mozesz wykorzystać do strumieniowego przesyłania danych do Kafki. \n",
    "Pozwala na to pythonowy `Producer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file stream.py\n",
    "\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "KAFKA_TOPIC = 'streaming'\n",
    "SERVER = \"broker:9092\"\n",
    "LAG = 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=[SERVER],\n",
    "        value_serializer=lambda x: json.dumps(x).encode(\"utf-8\"),\n",
    "        api_version=(3, 7, 0),\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            \n",
    "            t = datetime.now() + timedelta(seconds=random.randint(-15, 0))\n",
    "            \n",
    "            message = {\n",
    "                \"time\" : str(t),\n",
    "                \"id\" : random.choice([\"a\", \"b\", \"c\", \"d\", \"e\"]),\n",
    "                \"values\" : random.randint(0,100)\n",
    "            }\n",
    "            \n",
    "            producer.send(KAFKA_TOPIC, value=message)\n",
    "            sleep(LAG)\n",
    "    except KeyboardInterrupt:\n",
    "        producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchom kod poleceniem:\n",
    "```bash\n",
    "python stream.py\n",
    "```\n",
    "Następnie przejdź do nowego terminala i uruchom konsumenta (w konsoli)\n",
    "```bash\n",
    "kafka/bin/kafka-console-consumer.sh --bootstrap-server broker:9092 --topic streaming --from-beginning\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
