{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0089f716-08df-47ea-a459-c064c6ac10c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Przetwarzanie danych strumieniowych\n",
    "\n",
    "1. Sprawdź czy serwer Kafki posiada jakieś zdefiniowane topici:\n",
    "    - w dodatkowym oknie termianala wpisz polecenie:\n",
    "    ```bash\n",
    "    cd ~ \n",
    "    kafka/bin/kafka-topics.sh --list --bootstrap-server broker:9092\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00668246-0f77-4997-9a17-7cb2d12dd056",
   "metadata": {},
   "source": [
    "2. dodaj topic o nazwie `grupaXj1xx` Gdzie za `X` wstaw nr grupy a za `xx` nr swojego serwera\n",
    "```bash\n",
    "cd ~ \n",
    "kafka/bin/kafka-topics.sh --bootstrap-server broker:9092 --create --topic grupaXj1xx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612a460-0657-485b-a9f7-2e15b5632a2f",
   "metadata": {},
   "source": [
    "3. sprawdź listę tematów ponownie upewniając się, że posiadasz temat `grupaXj1xx`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ed426-cf12-48b7-afcd-82a88d56afa9",
   "metadata": {},
   "source": [
    "4. Uruchom nowy terminal na swoim komputerze i utwórz producenta generującego dane do nowego topicu\n",
    "```bash\n",
    "cd ~ \n",
    "kafka/bin/kafka-console-producer.sh --bootstrap-server broker:9092 --topic grupaXj1xx\n",
    "```\n",
    "\n",
    "Aby sprawdzić czy wysyłanie wiadomości działa uruchom kolejne okno terminala i wpisz następującą komendę realizującą konsumenta: \n",
    "\n",
    "```bash\n",
    "cd ~ \n",
    "kafka/bin/kafka-console-consumer.sh  --bootstrap-server broker:9092 --topic grupaXj1xx \n",
    "```\n",
    "Zweryfikuj, że przesyłanie danych działa. \n",
    "\n",
    "Zamknij okno producenta. Okno konsumenta zostaw otwarte - przyda się do weryfikacji automatu generującego dane. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798a36f-6909-415f-877b-5004c5c624cf",
   "metadata": {},
   "source": [
    "## Uruchomienie kodu wysyłającego strumień"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e14cb-dd1a-4fec-9015-08670683353e",
   "metadata": {},
   "source": [
    "Uzupełnij skrypt tak by generował następujące dane: \n",
    "\n",
    "1. utwórz zmienną `message` która będzie słownikiem zawierającym informacje pojedynczego eventu (klucz: wartość): \n",
    "    - \"time\" : aktualny czas w postaci stringu datetime.now()\n",
    "    - \"id\" : wybierane losowo z listy [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "    - \"value: losowa wartość z zakresu 0 do 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e8e038-4c02-4e2f-a9ef-dae6c2951a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stream.py\n"
     ]
    }
   ],
   "source": [
    "%%file stream.py\n",
    "\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "\n",
    "KAFKA_SERVER = \"broker:9092\"\n",
    "TOPIC = ...\n",
    "LAG = 2\n",
    "\n",
    "def create_producer(server):\n",
    "    return KafkaProducer(\n",
    "        bootstrap_servers=[server],\n",
    "        value_serializer=lambda x: json.dumps(x).encode(\"utf-8\"),\n",
    "        api_version=(3, 7, 0),\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    producer = create_producer(KAFKA_SERVER)\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "        ### TWOJ KOD \n",
    "            message = {}\n",
    "        ###    \n",
    "            producer.send(TOPIC, value=message)\n",
    "            sleep(LAG)\n",
    "    except KeyboardInterrupt:\n",
    "        producer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07229dc-b564-4e58-9136-0901f273f174",
   "metadata": {},
   "source": [
    "2.  w terminalu jupyterlab uruchom plik `stream.py`\n",
    "```bash\n",
    "python stream.py\n",
    "```\n",
    "\n",
    "sprawdz w oknie consumenta czy wysyłane wiadomości przychodzą do Kafki.\n",
    "\n",
    "Za uruchomienie importu kafka odpowiedzialna jest biblioteka `kafka-python`\n",
    "którą możesz zainstalować poleceniem `pip install kafka-python`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb725f-3075-42b0-9c39-d410894c4573",
   "metadata": {},
   "source": [
    "## APACHE SPARK \n",
    "\n",
    "Przygotuj kod skryptu który pobierze informacje z przesyłanego strumienia danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf9a50c-0463-4313-af82-17a3ed3e559b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%file app.py\n",
    "\n",
    "## LOAD SPARK SESSION object\n",
    "\n",
    "SERVER = \"broker:9092\"\n",
    "TOPIC = ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## create spark variable\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    ##  \n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "     \n",
    "    raw = (\n",
    "        spark.readStream\n",
    "        .format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", SERVER)\n",
    "        .option(\"subscribe\", TOPIC)\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "    query =  (\n",
    "        raw.writeStream\n",
    "        .outputMode(\"append\")\n",
    "        .format(\"console\")\n",
    "        .start()\n",
    "    )\n",
    "    \n",
    "    \n",
    "    query.awaitTermination()\n",
    "    query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350f4ec-8c47-4415-abbe-73a0d483e62e",
   "metadata": {},
   "source": [
    "uruchom pierwsze przetwarzanie strumienia: \n",
    "```bash\n",
    "spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1 app.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6518d0a-c874-412a-9800-1f41ee12ccfe",
   "metadata": {},
   "source": [
    "Zmodyfikuj pragram `app.py` dodając schemat:\n",
    "```python\n",
    "    json_schema = StructType(\n",
    "        [\n",
    "            StructField(\"time\", TimestampType()),\n",
    "            StructField(\"id\", StringType()),\n",
    "            StructField(\"value\", IntegerType()),\n",
    "        ]\n",
    "    )\n",
    "```\n",
    "Możesz również wykorzystać schemat ddl. \n",
    "\n",
    "\n",
    "Wczytaj zawartość zmiennej value wysyłanej z Kafki: \n",
    "nie zapomnij wczytać biblioteki `pyspark.sql.functions`\n",
    "\n",
    "```python\n",
    "    parsed = raw.select(\n",
    "        \"timestamp\", f.from_json(raw.value.cast(\"string\"), json_schema).alias(\"json\")\n",
    "    ).select(\n",
    "        f.col(\"timestamp\").alias(\"proc_time\"),\n",
    "        f.col(\"json\").getField(\"time\").alias(\"event_time\"),\n",
    "        f.col(\"json\").getField(\"id\").alias(\"id\"),\n",
    "        f.col(\"json\").getField(\"value\").alias(\"value\"),\n",
    "    )\n",
    "```\n",
    "lub wykorzystując funkcję dekodowania \n",
    "```python\n",
    "parsed = raw.select(\"timestamp\", f.from_json(f.decode(f.col(\"value\"), \"utf-8\"), schema).alias(\"values\")\n",
    "                   ).select(\"timestamp\", \"values.*\")\n",
    "```\n",
    "\n",
    "W wielu przykładach można znaleźć \n",
    "```python\n",
    "parsed = raw.selectExpr(\"cast(value as string) as value\") \n",
    "```\n",
    "Pomimo, iż kod ten będzie wyświetlał nam wiersz naszych danych to jest on traktowany jako string i nie będzie łatwo przetwarzać taki napis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a74acd-1c6b-4c37-a3ed-778b5d4d8585",
   "metadata": {},
   "source": [
    "uruchom kod sprawdzając czy widzisz przychodzące eventy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47232d0-418e-4cc2-a286-6a5a67425d0d",
   "metadata": {},
   "source": [
    "## zlicz ilość eventów ze względu na grupę ID \n",
    "\n",
    "uważaj na \n",
    "\n",
    "`Append output mode not supported when there are streaming aggregations on streaming DataFrames/DataSets without watermark;`\n",
    "\n",
    "Użyj \"complete\" albo \"update\"\n",
    "\n",
    "w tej prostej wersji możesz zmienić czas wykonywania obliczeń parametrem \n",
    "```python\n",
    "writeStream.trigger(processingTime='5 seconds')\n",
    "```\n",
    "## Przetwarzanie w oknach czasowych \n",
    "\n",
    "Aby wygenerować obliczanie grupowania w oknie typu tumblink window (jedno po drugim) użyj funkcji `window`  \n",
    "\n",
    "```python\n",
    "grouped = parsed.groupBy(f.window(\"timestamp\", \"5 seconds\"),\"id\").count()\n",
    "```\n",
    "\n",
    "korzystając z funkcji `window` możesz wskazać zmienną czasową oraz zrealizować okno typu sliding o długości np 10 sekund z uruchomieniem następnego okna po 5 sekundach. \n",
    "\n",
    "```python\n",
    "grouped = parsed.groupBy(f.window(\"timestamp\", \"10 seconds\", \"5 seconds\")).count()\n",
    "```\n",
    "\n",
    "Pamiętaj o sprawdzeniu opcji \"complete\" i \"update\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c8574-6a74-4467-bcff-0125faae398c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
